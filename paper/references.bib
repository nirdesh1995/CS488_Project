
@misc{jacob_text_2010,
	title = {Text {Classification} for {Sentiment} {Analysis} – {Stopwords} and {Collocations}},
	url = {https://streamhacker.com/2010/05/24/text-classification-sentiment-analysis-stopwords-collocations/},
	abstract = {Evaluation of how filtering stopwords and including bigram collocations affect the accuracy, precision, and recall of a Naive Bayes classifier used for sentiment analysis. Uses python NLTK and the movie reviews corpus with various feature extraction methods to train the Naive Bayes classifier for text categorization of positive and negative sentiment.},
	urldate = {2017-11-27},
	journal = {StreamHacker},
	author = {{Jacob}},
	month = may,
	year = {2010},
	file = {Snapshot:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/XTKIIT77/text-classification-sentiment-analysis-stopwords-collocations.html:text/html}
}

@misc{noauthor_stopwords_nodate,
	title = {On stopwords, filtering and data sparsity for sentiment analysis of {Twitter} - {Open} {Research} {Online}},
	url = {http://oro.open.ac.uk/40666/},
	urldate = {2017-11-27}
}

@inproceedings{asur_predicting_2010,
	title = {Predicting the {Future} with {Social} {Media}},
	volume = {1},
	doi = {10.1109/WI-IAT.2010.63},
	abstract = {In recent years, social media has become ubiquitous and important for social networking and content sharing. And yet, the content that is generated from these websites remains largely untapped. In this paper, we demonstrate how social media content can be used to predict real-world outcomes. In particular, we use the chatter from Twitter.com to forecast box-office revenues for movies. We show that a simple model built from the rate at which tweets are created about particular topics can outperform market-based predictors. We further demonstrate how sentiments extracted from Twitter can be utilized to improve the forecasting power of social media.},
	booktitle = {2010 {IEEE}/{WIC}/{ACM} {International} {Conference} on {Web} {Intelligence} and {Intelligent} {Agent} {Technology}},
	author = {Asur, S. and Huberman, B. A.},
	month = aug,
	year = {2010},
	keywords = {attention, content sharing, market-based predictors, prediction, social media, social media content, social networking, social networking (online), Twitter.com, Web sites},
	pages = {492--499},
	file = {IEEE Xplore Abstract Record:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/S556MCV8/5616710.html:text/html}
}

@inproceedings{gilbert_widespread_2010,
	title = {Widespread worry and the stock market},
	url = {https://experts.illinois.edu/en/publications/widespread-worry-and-the-stock-market},
	language = {English (US)},
	urldate = {2017-12-04},
	author = {Gilbert, Eric and Karahalios, Karrie},
	year = {2010},
	file = {Snapshot:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/BU2PZNRN/widespread-worry-and-the-stock-market.html:text/html}
}

@inproceedings{nasukawa_sentiment_2003,
	title = {Sentiment analysis: capturing favorability using natural language processing},
	isbn = {978-1-58113-583-1},
	shorttitle = {Sentiment analysis},
	url = {http://portal.acm.org/citation.cfm?doid=945645.945658},
	doi = {10.1145/945645.945658},
	language = {en},
	publisher = {ACM Press},
	author = {Nasukawa, Tetsuya and Yi, Jeonghee},
	year = {2003},
	pages = {70}
}

@article{poria_enhanced_2013,
	title = {Enhanced {SenticNet} with {Affective} {Labels} for {Concept}-{Based} {Opinion} {Mining}},
	volume = {28},
	issn = {1541-1672},
	doi = {10.1109/MIS.2013.4},
	abstract = {SenticNet 1.0 is one of the most widely used, publicly available resources for concept-based opinion mining. The presented methodology enriches SenticNet concepts with affective information by assigning an emotion label.},
	number = {2},
	journal = {IEEE Intelligent Systems},
	author = {Poria, S. and Gelbukh, A. and Hussain, A. and Howard, N. and Das, D. and Bandyopadhyay, S.},
	month = mar,
	year = {2013},
	keywords = {affective information, affective labels, concept-based opinion mining, data mining, emotion label, emotion lexicon, Emotion recognition, Feature extraction, Information analysis, Intelligent systems, Internet, Knowledge discovery, Natural language processing, opinion mining, sentic computing, SenticNet, SenticNet 1.0, SenticNet concepts, sentiment analysis, Vocabulary, WordNet-Affect},
	pages = {31--38},
	file = {IEEE Xplore Abstract Record:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/8GTEJJGZ/6415892.html:text/html}
}

@article{takala_gold-standard_2014,
	title = {Gold-standard for topic-specific sentiment analysis of economic texts},
	url = {https://research.aalto.fi/en/publications/goldstandard-for-topicspecific-sentiment-analysis-of-economic-texts(7964aed8-02d8-48b5-85eb-6eb79d4b0108)/export.html},
	language = {English},
	urldate = {2017-12-04},
	author = {Takala, Pyry and Malo, Pekka and Sinha, Ankur and Ahlgren, Oskar},
	year = {2014},
	file = {Snapshot:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/RUR5RTZA/export.html:text/html}
}

@inproceedings{saif_stopwords_2014,
	title = {On {Stopwords}, {Filtering} and {Data} {Sparsity} for {Sentiment} {Analysis} of {Twitter}},
	abstract = {Sentiment classification over Twitter is usually affected by the noisy nature (abbreviations, irregular forms) of tweets data. A popular procedure to reduce the noise of textual data is to remove stopwords by using pre-compiled stopword lists or more sophisticated methods for dynamic stopword identification. However, the effectiveness of removing stopwords in the context of Twitter sentiment classification has been debated in the last few years. In this paper we investigate whether removing stopwords helps or hampers the effectiveness of Twitter sentiment classification methods. To this end, we apply six different stopword identification methods to Twitter data from six different datasets and observe how removing stopwords affects two well-known supervised sentiment classification methods. We assess the impact of removing stopwords by observing fluctuations on the level of data sparsity, the size of the classifier's feature space and its classification performance. Our results show that using pre-compiled lists of stopwords negatively impacts the performance of Twitter sentiment classification approaches. On the other hand, the dynamic generation of stopword lists, by removing those infrequent terms appearing only once in the corpus, appears to be the optimal method to maintaining a high classification performance while reducing the data sparsity and shrinking the feature space by 0.37\% and 65\% on average respectively.},
	author = {Saif, Hassan and Fernandez, Miriam and He, Yulan and Alani, Harith},
	month = may,
	year = {2014}
}

@article{bollen_twitter_2011,
	title = {Twitter mood predicts the stock market},
	volume = {2},
	issn = {1877-7503},
	url = {http://www.sciencedirect.com/science/article/pii/S187775031100007X},
	doi = {10.1016/j.jocs.2010.12.007},
	abstract = {Behavioral economics tells us that emotions can profoundly affect individual behavior and decision-making. Does this also apply to societies at large, i.e. can societies experience mood states that affect their collective decision making? By extension is the public mood correlated or even predictive of economic indicators? Here we investigate whether measurements of collective mood states derived from large-scale Twitter feeds are correlated to the value of the Dow Jones Industrial Average (DJIA) over time. We analyze the text content of daily Twitter feeds by two mood tracking tools, namely OpinionFinder that measures positive vs. negative mood and Google-Profile of Mood States (GPOMS) that measures mood in terms of 6 dimensions (Calm, Alert, Sure, Vital, Kind, and Happy). We cross-validate the resulting mood time series by comparing their ability to detect the public's response to the presidential election and Thanksgiving day in 2008. A Granger causality analysis and a Self-Organizing Fuzzy Neural Network are then used to investigate the hypothesis that public mood states, as measured by the OpinionFinder and GPOMS mood time series, are predictive of changes in DJIA closing values. Our results indicate that the accuracy of DJIA predictions can be significantly improved by the inclusion of specific public mood dimensions but not others. We find an accuracy of 86.7\% in predicting the daily up and down changes in the closing values of the DJIA and a reduction of the Mean Average Percentage Error (MAPE) by more than 6\%.},
	number = {1},
	journal = {Journal of Computational Science},
	author = {Bollen, Johan and Mao, Huina and Zeng, Xiaojun},
	month = mar,
	year = {2011},
	keywords = {Collective mood, Sentiment tracking, Social networks, Stock market},
	pages = {1--8},
	file = {ScienceDirect Snapshot:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/NNEDEXRT/S187775031100007X.html:text/html}
}

@article{kalyani_stock_2016,
	title = {Stock trend prediction using news sentiment analysis},
	url = {http://arxiv.org/abs/1607.01958},
	abstract = {Efficient Market Hypothesis is the popular theory about stock prediction. With its failure much research has been carried in the area of prediction of stocks. This project is about taking non quantifiable data such as financial news articles about a company and predicting its future stock trend with news sentiment classification. Assuming that news articles have impact on stock market, this is an attempt to study relationship between news and stock trend. To show this, we created three different classification models which depict polarity of news articles being positive or negative. Observations show that RF and SVM perform well in all types of testing. Na{\textbackslash}"ive Bayes gives good result but not compared to the other two. Experiments are conducted to evaluate various aspects of the proposed model and encouraging results are obtained in all of the experiments. The accuracy of the prediction model is more than 80\% and in comparison with news random labeling with 50\% of accuracy; the model has increased the accuracy by 30\%.},
	journal = {arXiv:1607.01958 [cs]},
	author = {Kalyani, Joshi and Bharathi, Prof H. N. and Jyothi, Prof Rao},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.01958},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Learning},
	annote = {Comment: 11 PAGES, 4 FIGURES},
	file = {arXiv\:1607.01958 PDF:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/ZR22GPW7/Kalyani et al. - 2016 - Stock trend prediction using news sentiment analys.pdf:application/pdf;arXiv.org Snapshot:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/C6CNA78S/1607.html:text/html}
}

@article{kirange_open_nodate,
	title = {Open {Journal} {Systems}},
	url = {https://www.ijact.in/index.php/ijact/article/view/473},
	doi = {http://dx.doi.org/10.6084/ijact.v5i3.473},
	abstract = {Stock market data analysis needs the help of artificial intelligence and data mining techniques. The volatility of stock prices depends on gains or losses of certain companies. News articles are one of the most important factors which influence the stock market. This study basically shows the effect of emotion classification of financial news to the prediction of stock market prices. In order to find correlation between sentiment predicted from news and original stock price and to test efficient market hypothesis, we plot the sentiments of two companies (Infosys and Wipro) over a period of 10 years. For emotion classification, various classifiers such as Naive Bayes, Knn and SVM are evaluated. The comparison between positive sentiment curve and stock price trends reveals co-relation between them.},
	urldate = {2017-12-09},
	author = {Kirange, Mr D. K. and Deshmukh, Dr Ratnadeep R.},
	keywords = {Computer Science Journal, Computer Science Journals, energy technology, fluid mechanics, International Journal of Computer Science, Journal of Computer Science, mechanical engineering, operation research, production management, structural engineering, thermal engineering},
	file = {Snapshot:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/T2WCWIS4/473.html:text/html}
}

@misc{business-science.io_tidy_2017,
	title = {Tidy {Time} {Series} {Analysis}, {Part} 3: {The} {Rolling} {Correlation}},
	shorttitle = {Tidy {Time} {Series} {Analysis}, {Part} 3},
	url = {http://www.business-science.io/timeseries-analysis/2017/07/30/tidy-timeseries-analysis-pt-3.html},
	abstract = {In the third part in a series on Tidy Time Series Analysis, we’ll use the runCor function from TTR to investigate rolling (dynamic) correlations. We’ll again use tidyquant to investigate CRAN downloads. This time we’ll also get some help from the corrr package to investigate correlations over specific timespans, and the cowplot package for multi-plot visualizations. We’ll end by reviewing the changes in rolling correlations to show how to detect events and shifts in trend. If you like what you read, please follow us on social media to stay up on the latest Business Science news, events and information! As always, we are interested in both expanding our network of data scientists and seeking new clients interested in applying data science to business and finance. If interested, contact us.},
	urldate = {2017-12-11},
	journal = {Business Science},
	author = {business-science.io},
	month = jul,
	year = {2017},
	file = {Snapshot:/Users/nirdeshbhandari/Library/Application Support/Zotero/Profiles/ahsn9ojp.default/zotero/storage/BTX3UWHC/tidy-timeseries-analysis-pt-3.html:text/html}
}